# Open-LLM-VTuber RunPod Environment Configuration
# Copy this file to .env and fill in your values

# ============================================
# LLM Configuration
# ============================================

# Ollama model to use (will be auto-downloaded on first run)
# Options: qwen2.5:7b, qwen2.5:14b, qwen2.5:32b, llama3.3:70b-instruct-q4_K_M
OLLAMA_MODEL=qwen2.5:32b

# ============================================
# Cloud LLM API Keys (Optional)
# ============================================

# OpenAI API Key (for GPT-4 fallback)
OPENAI_API_KEY=

# Anthropic API Key (for Claude fallback)
ANTHROPIC_API_KEY=

# Groq API Key (for fast cloud inference)
# Get free API key at: https://console.groq.com
GROQ_API_KEY=

# Google Gemini API Key
GEMINI_API_KEY=

# DeepSeek API Key
DEEPSEEK_API_KEY=

# Mistral API Key
MISTRAL_API_KEY=

# ============================================
# Security Configuration
# ============================================

# API Key for authentication (highly recommended for production)
# Generate with: openssl rand -base64 32
API_KEY=

# ============================================
# Model Cache Configuration
# ============================================

# HuggingFace cache directory
HF_HOME=/workspace/models

# ModelScope cache directory (for Chinese users)
MODELSCOPE_CACHE=/workspace/models

# Use HuggingFace mirror (for users in China)
# HF_ENDPOINT=https://hf-mirror.com

# ============================================
# Character Configuration
# ============================================

# Character config to use (from characters/ folder)
# Options: rtx5090-balanced, rtx5090-performance, rtx5090-quality,
#          rtx5090-budget, rtx5090-multilingual, mao_pro
CHARACTER_CONFIG=rtx5090-balanced

# ============================================
# RunPod Specific
# ============================================

# These are automatically set by RunPod
# RUNPOD_POD_ID=
# RUNPOD_PUBLIC_IP=

# ============================================
# Advanced Settings
# ============================================

# Logging level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Server host (0.0.0.0 for RunPod, localhost for local)
SERVER_HOST=0.0.0.0

# Server port
SERVER_PORT=12393

# Enable verbose mode
# VERBOSE=true

# ============================================
# TTS Service Configuration (Optional)
# ============================================

# Fish Audio API (for high-quality TTS)
FISH_API_KEY=

# Fish Audio reference ID (voice to clone)
FISH_REFERENCE_ID=

# ElevenLabs API Key
ELEVENLABS_API_KEY=

# ElevenLabs Voice ID
ELEVENLABS_VOICE_ID=

# Azure TTS (Microsoft)
AZURE_TTS_KEY=
AZURE_TTS_REGION=

# ============================================
# Translation Services (Optional)
# ============================================

# DeepL API Key (for translation)
DEEPL_API_KEY=

# Tencent Cloud (for Chinese users)
TENCENT_SECRET_ID=
TENCENT_SECRET_KEY=

# ============================================
# Live Streaming Integration (Optional)
# ============================================

# Bilibili Live Room IDs (comma-separated)
BILIBILI_ROOM_IDS=

# Bilibili SESSDATA cookie
BILIBILI_SESSDATA=

# ============================================
# Performance Tuning
# ============================================

# PyTorch threads
# OMP_NUM_THREADS=8

# CUDA device (0 for first GPU, 1 for second, etc.)
# CUDA_VISIBLE_DEVICES=0

# ============================================
# Notes
# ============================================

# 1. Never commit .env files to Git!
# 2. Generate strong API keys for production
# 3. Restart container after changing values
# 4. Check logs if something doesn't work
