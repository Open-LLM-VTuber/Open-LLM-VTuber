version: "3.9"
services:
  open-llm-vtuber:
    image: open-llm-vtuber   # Add :tag if needed
    # container_name: open-llm-vtuber
    build:
      context: ../
      dockerfile: dockerfiles/dockerfile   # Must match your actual filename
    ports:
      - "12393:12393"   # ✅ Only expose the application port
    environment:
      - OLLAMA_DEFAULT_MODEL=deepseek-r1:8b
    volumes:
      - ollama_data:/root/.ollama   # ✅ Persistent cache for models
      - models_data:/app/models     # ✅ Application cache
      # - ./conf:/app/conf:ro       # (Optional) User configuration directory
    restart: unless-stopped

volumes:
  ollama_data:
  models_data:
