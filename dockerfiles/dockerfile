# ================================
# All-in-one: Ollama + App
# ================================
FROM ollama/ollama:latest AS ollama-src
FROM python:3.10-slim AS base

# Tsinghua Source
ARG PIP_INDEX_URL=https://pypi.tuna.tsinghua.edu.cn/simple
ARG PIP_DEFAULT_TIMEOUT=120
ENV PIP_INDEX_URL=${PIP_INDEX_URL} \
    PIP_DEFAULT_TIMEOUT=${PIP_DEFAULT_TIMEOUT}

ENV DEBIAN_FRONTEND=noninteractive \
    PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PIP_NO_CACHE_DIR=1 \
    UV_LINK_MODE=copy \
    CONFIG_FILE=/app/conf/conf.yaml

WORKDIR /app

# Base dependencies
RUN apt-get update -o Acquire::Retries=5 \
 && apt-get install -y --no-install-recommends \
      ffmpeg git curl ca-certificates \
 && rm -rf /var/lib/apt/lists/*

# Install uv
COPY --from=ghcr.io/astral-sh/uv:latest /uv /uvx /usr/local/bin/

# Install Ollama
COPY --from=ollama/ollama:latest /bin/ollama /usr/local/bin/ollama

# Pre-install dependencies (leverage cache)
COPY pyproject.toml uv.lock ./
RUN --mount=type=cache,target=/root/.cache/uv \
    uv sync --frozen --no-dev

# Copy source code and install project (without re-installing deps)
COPY . /app
RUN uv pip install --no-deps .

RUN printf '%s\n' \
  '#!/usr/bin/env sh' \
  'set -eu' \
  '' \
  '# 0) Ensure unified mount dir exists' \
  'mkdir -p /app/conf' \
  '' \
  '# 1) Handle conf.yaml: MUST be provided by user — no default allowed!' \
  'if [ -f "/app/conf/conf.yaml" ]; then' \
  '  echo "Using user-provided conf.yaml"' \
  '  ln -sf /app/conf/conf.yaml /app/conf.yaml' \
  'else' \
  '  echo "ERROR: Missing required configuration file!" >&2' \
  '  echo "Please mount your config directory to /app/conf containing \"conf.yaml\"." >&2' \
  '  echo "Example: -v \$(pwd)/my-config:/app/conf" >&2' \
  '  echo "The directory must contain: conf.yaml (required), and optionally model_dict.json, live2d-models/, characters/." >&2' \
  '  exit 1' \
  'fi' \
  '' \
  '# 2) Handle model_dict.json (optional)' \
  'if [ -f "/app/conf/model_dict.json" ]; then' \
  '  echo "Using user-provided model_dict.json"' \
  '  ln -sf /app/conf/model_dict.json /app/model_dict.json' \
  'elif [ -f "/app/config_templates/model_dict.json" ]; then' \
  '  cp /app/config_templates/model_dict.json /app/model_dict.json' \
  'fi' \
  '' \
  '# 3) Handle live2d-models (optional directory)' \
  'if [ -d "/app/conf/live2d-models" ]; then' \
  '  echo "Using user-provided live2d-models"' \
  '  rm -rf /app/live2d-models && ln -s /app/conf/live2d-models /app/live2d-models' \
  'elif [ -d "/app/config_templates/live2d-models" ]; then' \
  '  cp -r /app/config_templates/live2d-models /app/live2d-models' \
  'fi' \
  '' \
  '# 4) Handle characters (optional directory)' \
  'if [ -d "/app/conf/characters" ]; then' \
  '  echo "Using user-provided characters"' \
  '  rm -rf /app/characters && ln -s /app/conf/characters /app/characters' \
  'elif [ -d "/app/config_templates/characters" ]; then' \
  '  cp -r /app/config_templates/characters /app/characters' \
  'fi' \
  '' \
  '# 5) Start Ollama (internal only)' \
  'export OLLAMA_HOST="${OLLAMA_HOST:-127.0.0.1:11434}"' \
  'ollama serve >/var/log/ollama.log 2>&1 &' \
  '' \
  '# 6) Wait for Ollama ready (max 60s)' \
  'for i in $(seq 1 60); do' \
  '  if curl -fsS "http://127.0.0.1:11434/v1/models" >/dev/null 2>&1; then' \
  '    echo "Ollama ready"' \
  '    break' \
  '  fi' \
  '  sleep 1' \
  '  if [ "$i" -eq 60 ]; then' \
  '    echo "ERROR: Ollama did not become ready within 60s" >&2' \
  '    exit 1' \
  '  fi' \
  'done' \
  '' \
  '# 7) Optional: pre-pull default model' \
  'if [ -n "${OLLAMA_DEFAULT_MODEL:-}" ]; then' \
  '  ollama list | grep -q "^${OLLAMA_DEFAULT_MODEL} " || ollama pull "$OLLAMA_DEFAULT_MODEL" || true' \
  'fi' \
  '' \
  '# 8) Start app' \
  'exec uv run run_server.py' \
  > /usr/local/bin/start-all && chmod +x /usr/local/bin/start-all

# Volumes: ollama cache, models, and unified config mount (conf.yaml + live2d-models + characters)
VOLUME ["/root/.ollama", "/app/models", "/app/conf"]

# ✅ Only expose the app port (Ollama is not exposed externally)
EXPOSE 12393

ARG OLLAMA_DEFAULT_MODEL=
ENV OLLAMA_DEFAULT_MODEL=${OLLAMA_DEFAULT_MODEL}

CMD ["/usr/local/bin/start-all"]